{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP (Natural Language Processing) with Python\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.mlab as mlab\n",
    "import warnings\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#import xgboost, numpy, textblob, string\n",
    "#from keras.preprocessing import text, sequence\n",
    "#from keras import layers, models, optimizers\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn import svm\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Get the Data **\n",
    "This is the data set provided in kaggle  https://www.kaggle.com/c/nlp-getting-started/data\n",
    "What am I predicting?\n",
    "You are predicting whether a given tweet is about a real disaster or not. If so, predict a 1. If not, predict a 0.\n",
    "Files\n",
    "train.csv - the training set\n",
    "test.csv - the test set\n",
    "sample_submission.csv - a sample submission file in the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "file_path = 'C:\\\\Users\\\\vreddyj\\\\pandas\\\\data\\\\NLP_train.csv'\n",
    "file_path2 = 'C:\\\\Users\\\\vreddyj\\\\pandas\\\\data\\\\NLP_test.csv'\n",
    "\n",
    "train_df = pd.read_csv(file_path)\n",
    "test_df = pd.read_csv(file_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA - Exploratory Data Analysis\n",
    "Let's explore the data - Let's check out some of the stats with some plots and the built-in methods in pandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      "id          7613 non-null int64\n",
      "keyword     7552 non-null object\n",
      "location    5080 non-null object\n",
      "text        7613 non-null object\n",
      "target      7613 non-null int64\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>7613.0</td>\n",
       "      <td>5441.934848</td>\n",
       "      <td>3137.11609</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2734.0</td>\n",
       "      <td>5408.0</td>\n",
       "      <td>8146.0</td>\n",
       "      <td>10873.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>7613.0</td>\n",
       "      <td>0.429660</td>\n",
       "      <td>0.49506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count         mean         std  min     25%     50%     75%      max\n",
       "id      7613.0  5441.934848  3137.11609  1.0  2734.0  5408.0  8146.0  10873.0\n",
       "target  7613.0     0.429660     0.49506  0.0     0.0     0.0     1.0      1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.info()\n",
    "train_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records and columns  -  train data (7613, 5)\n",
      "Field names : ['id' 'keyword' 'location' 'text' 'target']\n",
      "column wise total null counts \n",
      " location    2533\n",
      "keyword       61\n",
      "target         0\n",
      "text           0\n",
      "id             0\n",
      "dtype: int64\n",
      "column wise total null count percentages \n",
      " location    33.272035\n",
      "keyword      0.801261\n",
      "target       0.000000\n",
      "text         0.000000\n",
      "id           0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records and columns  -  train data\", train_df.shape)\n",
    "print(\"Field names :\", train_df.columns.values)\n",
    "#HANDLING MISSING DATA\n",
    "total = train_df.isnull().sum().sort_values(ascending = False)\n",
    "print(\"column wise total null counts\",'\\n',total)\n",
    "percent = (train_df.isnull().sum()/train_df.isnull().count()*100).sort_values(ascending = False)\n",
    "print(\"column wise total null count percentages\",'\\n', percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4342.0</td>\n",
       "      <td>5276.446338</td>\n",
       "      <td>3157.206802</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2513.25</td>\n",
       "      <td>5243.5</td>\n",
       "      <td>8038.5</td>\n",
       "      <td>10848.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3271.0</td>\n",
       "      <td>5661.608071</td>\n",
       "      <td>3097.094809</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3104.50</td>\n",
       "      <td>5676.0</td>\n",
       "      <td>8252.0</td>\n",
       "      <td>10873.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                                           \\\n",
       "         count         mean          std   min      25%     50%     75%   \n",
       "target                                                                    \n",
       "0       4342.0  5276.446338  3157.206802  23.0  2513.25  5243.5  8038.5   \n",
       "1       3271.0  5661.608071  3097.094809   1.0  3104.50  5676.0  8252.0   \n",
       "\n",
       "                 \n",
       "            max  \n",
       "target           \n",
       "0       10848.0  \n",
       "1       10873.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('target').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  length  \n",
       "0       1      69  \n",
       "1       1      38  \n",
       "2       1     133  \n",
       "3       1      65  \n",
       "4       1      88  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['length'] = train_df['text'].apply(len)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['length'] = test_df['text'].apply(len)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d9725c5ef0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['length'].plot(bins=50, kind='hist')\n",
    "test_df['length'].plot(bins=50, kind='hist') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7613.000000\n",
       "mean      101.037436\n",
       "std        33.781325\n",
       "min         7.000000\n",
       "25%        78.000000\n",
       "50%       107.000000\n",
       "75%       133.000000\n",
       "max       157.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.length.describe()\n",
    "#test_df.length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"when you're taking a shower and someone flushes the toilet and you have .1 second to GTFO or you get burned??????????????????????????????????????????????????\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['length'] == 157]['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x000001D97259AD68>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x000001D972785F98>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.hist(column='length', by='target', bins=50,figsize=(12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-processing\n",
    "Our main issue with our data is that it is all in text format (strings). The classification algorithms that we've learned about so far will need some sort of numerical feature vector in order to perform the classification task. There are actually many methods to convert a corpus to a vector format. The simplest is the the bag-of-words approach, where each unique word in a text will be represented by one number.\n",
    "\n",
    "In this section we'll convert the raw messages (sequence of characters) into vectors (sequences of numbers).\n",
    "\n",
    "As a first step, let's write a function that will split a message into its individual words and return a list. We'll also remove very common words, ('the', 'a', etc..). To do this we will take advantage of the NLTK library. It's pretty much the standard library in Python for processing text and has a lot of useful features. We'll only use some of the basic ones here.\n",
    "\n",
    "Let's create a function that will process the string in the message column, then we can just use apply() in pandas do process all the text in the DataFrame.\n",
    "\n",
    "First removing punctuation. We can just take advantage of Python's built-in string library to get a quick list of all the possible punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')[0:10] # Show some stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Deeds, Reason, earthquake, May, ALLAH, Forgiv...\n",
       "1        [Forest, fire, near, La, Ronge, Sask, Canada]\n",
       "2    [residents, asked, shelter, place, notified, o...\n",
       "3    [13000, people, receive, wildfires, evacuation...\n",
       "4    [got, sent, photo, Ruby, Alaska, smoke, wildfi...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure its working\n",
    "train_df['text'].head(5).apply(text_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "Currently, we have the messages as lists of tokens (also known as lemmas) and now we need to convert each of those messages into a vector the SciKit Learn's algorithm models can work with.\n",
    "\n",
    "Now we'll convert each message, represented as a list of tokens (lemmas) above, into a vector that machine learning models can understand.\n",
    "\n",
    "We'll do that in three steps using the bag-of-words model:\n",
    "\n",
    "Count how many times does a word occur in each message (Known as term frequency)\n",
    "\n",
    "Weigh the counts, so that frequent tokens get lower weight (inverse document frequency)\n",
    "\n",
    "Normalize the vectors to unit length, to abstract from the original text length (L2 norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26473\n"
     ]
    }
   ],
   "source": [
    "# Might take awhile...\n",
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(train_df['text'])\n",
    "\n",
    "# Print total number of vocab words\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13,000 people receive #wildfires evacuation orders in California \n"
     ]
    }
   ],
   "source": [
    "text4 = train_df['text'][3]\n",
    "print(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 144)\t1\n",
      "  (0, 2334)\t1\n",
      "  (0, 14502)\t1\n",
      "  (0, 22409)\t1\n",
      "  (0, 22635)\t1\n",
      "  (0, 23345)\t1\n",
      "  (0, 26071)\t1\n",
      "(1, 26473)\n"
     ]
    }
   ],
   "source": [
    "bow4 = bow_transformer.transform([text4])\n",
    "print(bow4)\n",
    "print(bow4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000\n",
      "wildfires\n"
     ]
    }
   ],
   "source": [
    "print(bow_transformer.get_feature_names()[144])\n",
    "print(bow_transformer.get_feature_names()[26071])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_bow = bow_transformer.transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (7613, 26473)\n",
      "Amount of Non-Zero occurences:  75006\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Sparse Matrix: ', messages_bow.shape)\n",
    "print('Amount of Non-Zero occurences: ', messages_bow.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0\n"
     ]
    }
   ],
   "source": [
    "sparsity = (100.0 * messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1]))\n",
    "print('sparsity: {}'.format(round(sparsity)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF, using scikit-learn's TfidfTransformer\n",
    "After the counting, the term weighting and normalization can be done with TF-IDF, using scikit-learn's TfidfTransformer.\n",
    "So what is TF-IDF?\n",
    "TF-IDF stands for term frequency-inverse document frequency, and the tf-idf weight is a weight often used in information retrieval and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus. Variations of the tf-idf weighting scheme are often used by search engines as a central tool in scoring and ranking a document's relevance given a user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 26071)\t0.4024513325168046\n",
      "  (0, 23345)\t0.4718026141633829\n",
      "  (0, 22635)\t0.25921479580657425\n",
      "  (0, 22409)\t0.39780696282539063\n",
      "  (0, 14502)\t0.3391667965318131\n",
      "  (0, 2334)\t0.2781109881741682\n",
      "  (0, 144)\t0.44453648958637354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "tfidf4 = tfidf_transformer.transform(bow4)\n",
    "print(tfidf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.948759890378168\n",
      "7.539848664144072\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_transformer.idf_[bow_transformer.vocabulary_['u']])\n",
    "print(tfidf_transformer.idf_[bow_transformer.vocabulary_['wildfires']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 26473)\n"
     ]
    }
   ],
   "source": [
    "messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "print(messages_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model\n",
    "With messages represented as vectors, we can finally train our spam/ham classifier. Now we can actually use almost any sort of classification algorithms. For a variety of reasons, the Naive Bayes classifier algorithm is a good choice.\n",
    "\n",
    "We'll be using scikit-learn here, choosing the Naive Bayes classifier to start with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "disaster_detect_model = MultinomialNB().fit(messages_tfidf, train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: 1\n",
      "expected: 1\n"
     ]
    }
   ],
   "source": [
    "print('predicted:', disaster_detect_model.predict(tfidf4)[0])\n",
    "print('expected:', train_df.target[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "all_predictions = disaster_detect_model.predict(messages_tfidf)\n",
    "print(all_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "Now we want to determine how well our model will do overall on the entire dataset. Let's begin by getting all the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      4342\n",
      "           1       0.97      0.83      0.89      3271\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      7613\n",
      "   macro avg       0.93      0.90      0.91      7613\n",
      "weighted avg       0.92      0.91      0.91      7613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(train_df['target'], all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data accuracy is: \n",
      "0.9143570208853278\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "print(\"All data accuracy is: \")\n",
    "print(accuracy_score(train_df['target'], all_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6090 1523 7613\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "msg_train, msg_test, label_train, label_test = \\\n",
    "train_test_split(train_df['text'], train_df['target'], test_size=0.2)\n",
    "\n",
    "print(len(msg_train), len(msg_test), len(msg_train) + len(msg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Data Pipeline\n",
    "Let's run our model again and then predict off the test set. We will use SciKit Learn's pipeline capabilities to store a pipeline of workflow. This will allow us to set up all the transformations that we will do to the data for future use. Let's see an example of how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function text_process at 0x000001D9727659D8>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocesso...f=False, use_idf=True)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(msg_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = pipeline.predict(msg_train)\n",
    "predictions_test = pipeline.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93      3853\n",
      "           1       0.84      0.97      0.90      2237\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      6090\n",
      "   macro avg       0.91      0.93      0.92      6090\n",
      "weighted avg       0.93      0.92      0.92      6090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions_train,label_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82      1025\n",
      "           1       0.62      0.83      0.71       498\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1523\n",
      "   macro avg       0.76      0.79      0.76      1523\n",
      "weighted avg       0.81      0.78      0.78      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions_test,label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data accuracy is: \n",
      "0.9198686371100164\n",
      "test data accuracy is: \n",
      "0.7754432042022325\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "print(\"NB-Train data accuracy is: \")\n",
    "print(accuracy_score(label_train, predictions_train))\n",
    "# Test accuracy\n",
    "print(\"NB- test data accuracy is: \")\n",
    "print(accuracy_score(label_test, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_ftest = test_df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us predict the actual testdata/the goal of the competition is to predict for this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ftest = pipeline.predict(msg_ftest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us try random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier pipeline\n",
    "pipeline_rf = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', RandomForestClassifier()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf.fit(msg_train,label_train)\n",
    "predictions_train = pipeline_rf.predict(msg_train)\n",
    "predictions_test = pipeline_rf.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      3633\n",
      "           1       0.94      0.99      0.97      2457\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      6090\n",
      "   macro avg       0.97      0.98      0.97      6090\n",
      "weighted avg       0.97      0.97      0.97      6090\n",
      "\n",
      "RF - Train data accuracy is: \n",
      "0.9720853858784894\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions_train,label_train))\n",
    "# Test accuracy\n",
    "print(\"RF - Train data accuracy is: \")\n",
    "print(accuracy_score(label_train, predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.72      0.80      1052\n",
      "           1       0.56      0.80      0.66       471\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      1523\n",
      "   macro avg       0.73      0.76      0.73      1523\n",
      "weighted avg       0.79      0.75      0.75      1523\n",
      "\n",
      "RF - Test data accuracy is: \n",
      "0.7458962573867367\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions_test,label_test))\n",
    "# Test accuracy\n",
    "print(\"RF - Test data accuracy is: \")\n",
    "print(accuracy_score(label_test, predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us predict the actual testdata/the goal of the competition is to predict for this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ftest = pipeline_rf.predict(msg_ftest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading the results in to csv file\n",
    "rad the sample file from desktop\n",
    "make a data frame and write the target predictions and \n",
    "write the final results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path3 = \"C:\\\\Users\\\\vreddyj\\\\Desktop\\\\BM_2018\\\\Ineuron\\\\Natural-Language-Processing-master\\\\NLP-Kaggle\\\\submission.csv\"\n",
    "sample_submission = pd.read_csv(file_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[\"target\"] = predictions_ftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       0\n",
       "4  11       1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive bias results\n",
    "sample_submission.to_csv(\"submission_371040.csv\", index=False)\n",
    "#File saved in path C:\\VTRoot\\HarddiskVolume4\\Users\\vreddyj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest results\n",
    "sample_submission.to_csv(\"submission_rf.csv\", index=False)\n",
    "#File saved in path C:\\VTRoot\\HarddiskVolume4\\Users\\vreddyj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@waliamrinal/saving-a-pandas-dataframe-as-a-csv-file-4f8b74b7a1bc\n",
    "sample_submission.to_csv(r'C:\\\\Users\\\\vreddyj\\\\Desktop\\\\submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(r'C:\\Users\\vreddyj\\Desktop\\submission3.csv', index=False)\n",
    "#file save in path C:\\VTRoot\\HarddiskVolume4\\Users\\vreddyj\\Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(r'C:\\Users\\vreddyj\\Desktop\\file.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
